{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\u0000i\u0000n\u0000d\u0000o\u0000w\u0000s\u0000 \u0000S\u0000u\u0000b\u0000s\u0000y\u0000s\u0000t\u0000e\u0000m\u0000 \u0000f\u0000o\u0000r\u0000 \u0000L\u0000i\u0000n\u0000u\u0000x\u0000 \u0000h\u0000a\u0000s\u0000 \u0000n\u0000o\u0000 \u0000i\u0000n\u0000s\u0000t\u0000a\u0000l\u0000l\u0000e\u0000d\u0000 \u0000d\u0000i\u0000s\u0000t\u0000r\u0000i\u0000b\u0000u\u0000t\u0000i\u0000o\u0000n\u0000s\u0000.\u0000\n",
      "\u0000\n",
      "\u0000\n",
      "\u0000D\u0000i\u0000s\u0000t\u0000r\u0000i\u0000b\u0000u\u0000t\u0000i\u0000o\u0000n\u0000s\u0000 \u0000c\u0000a\u0000n\u0000 \u0000b\u0000e\u0000 \u0000i\u0000n\u0000s\u0000t\u0000a\u0000l\u0000l\u0000e\u0000d\u0000 \u0000b\u0000y\u0000 \u0000v\u0000i\u0000s\u0000i\u0000t\u0000i\u0000n\u0000g\u0000 \u0000t\u0000h\u0000e\u0000 \u0000M\u0000i\u0000c\u0000r\u0000o\u0000s\u0000o\u0000f\u0000t\u0000 \u0000S\u0000t\u0000o\u0000r\u0000e\u0000:\u0000\n",
      "\u0000\n",
      "\u0000\n",
      "\u0000h\u0000t\u0000t\u0000p\u0000s\u0000:\u0000/\u0000/\u0000a\u0000k\u0000a\u0000.\u0000m\u0000s\u0000/\u0000w\u0000s\u0000l\u0000s\u0000t\u0000o\u0000r\u0000e\u0000\n",
      "\u0000\n",
      "\u0000\n",
      "\u0000\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "if 'google.colab' in sys.modules and not os.path.exists('.setup_complete'):\n",
    "    !wget -q https://raw.githubusercontent.com/yandexdataschool/Practical_RL/master/setup_colab.sh -O- | bash\n",
    "\n",
    "    !touch .setup_complete\n",
    "\n",
    "# This code creates a virtual display to draw game images on.\n",
    "# It will have no effect if your machine has a monitor.\n",
    "if type(os.environ.get(\"DISPLAY\")) is not str or len(os.environ.get(\"DISPLAY\")) == 0:\n",
    "    !bash ../xvfb start\n",
    "    os.environ['DISPLAY'] = ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OpenAI Gym\n",
    "\n",
    "We're gonna spend several next weeks learning algorithms that solve decision processes. We are then in need of some interesting decision problems to test our algorithms.\n",
    "\n",
    "That's where OpenAI Gym comes into play. It's a Python library that wraps many classical decision problems including robot control, videogames and board games.\n",
    "\n",
    "So here's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box([-1.2  -0.07], [0.6  0.07], (2,), float32)\n",
      "Action space: Discrete(3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adhocmaster\\anaconda3\\envs\\gymnes\\lib\\site-packages\\pyglet\\image\\codecs\\wic.py:289: UserWarning: [WinError -2147417850] Cannot change thread mode after it is set\n",
      "  warnings.warn(str(err))\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "env = gym.make(\"MountainCar-v0\")\n",
    "env.reset()\n",
    "env.render('rgb_array')\n",
    "# plt.imshow(env.render('rgb_array'))\n",
    "print(\"Observation space:\", env.observation_space)\n",
    "print(\"Action space:\", env.action_space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: if you're running this on your local machine, you'll see a window pop up with the image above. Don't close it, just alt-tab away."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gym interface\n",
    "\n",
    "The three main methods of an environment are\n",
    "* `reset()`: reset environment to the initial state, _return first observation_\n",
    "* `render()`: show current environment state (a more colorful version :) )\n",
    "* `step(a)`: commit action `a` and return `(new_observation, reward, is_done, info)`\n",
    " * `new_observation`: an observation right after committing the action `a`\n",
    " * `reward`: a number representing your reward for committing action `a`\n",
    " * `is_done`: True if the MDP has just finished, False if still in progress\n",
    " * `info`: some auxiliary stuff about what just happened. For now, ignore it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial observation code: [-0.57424307  0.        ]\n"
     ]
    }
   ],
   "source": [
    "obs0 = env.reset()\n",
    "env.render()\n",
    "print(\"initial observation code:\", obs0)\n",
    "\n",
    "# Note: in MountainCar, observation is just two numbers: car position and velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "taking action 2 (right)\n",
      "new observation code: [-0.5728647   0.00137837]\n",
      "reward: -1.0\n",
      "is game over?: False\n"
     ]
    }
   ],
   "source": [
    "print(\"taking action 2 (right)\")\n",
    "new_obs, reward, is_done, _ = env.step(2)\n",
    "env.render()\n",
    "\n",
    "print(\"new observation code:\", new_obs)\n",
    "print(\"reward:\", reward)\n",
    "print(\"is game over?:\", is_done)\n",
    "\n",
    "# Note: as you can see, the car has moved to the right slightly (around 0.0005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play with it\n",
    "\n",
    "Below is the code that drives the car to the right. However, if you simply use the default policy, the car will not reach the flag at the far right due to gravity.\n",
    "\n",
    "__Your task__ is to fix it. Find a strategy that reaches the flag. \n",
    "\n",
    "You are not required to build any sophisticated algorithms for now, and you definitely don't need to know any reinforcement learning for this. Feel free to hard-code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython import display\n",
    "\n",
    "# Create env manually to set time limit. Please don't change this.\n",
    "TIME_LIMIT = 250\n",
    "# env = gym.wrappers.TimeLimit(\n",
    "#     gym.envs.classic_control.MountainCarEnv(),\n",
    "#     max_episode_steps=TIME_LIMIT + 1,\n",
    "# )\n",
    "actions = {'left': 0, 'stop': 1, 'right': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevPos = None\n",
    "prevV = None\n",
    "def policy(obs, t):\n",
    "    global prevPos, prevV\n",
    "    # Write the code for your policy here. You can use the observation\n",
    "    # (a tuple of position and velocity), the current time step, or both,\n",
    "    # if you want.\n",
    "    position, velocity = obs\n",
    "    \n",
    "    # This is an example policy. You can try running it, but it will not work.\n",
    "    # Your goal is to fix that. You don't need anything sophisticated here,\n",
    "    # and you can hard-code any policy that seems to work.\n",
    "    # Hint: think how you would make a swing go farther and faster.\n",
    "    # return actions['right']\n",
    "    if prevPos is None:\n",
    "        prevPos = position\n",
    "        prevV = velocity\n",
    "        return np.random.choice([0, 2])\n",
    "    \n",
    "    # if car is going up, push up, if going down, push down.\n",
    "    if velocity == 0.0:\n",
    "        # print(\"velocity is 0\")\n",
    "        prevPos = position\n",
    "        if prevV > 0:\n",
    "            prevV = velocity\n",
    "            return actions['left']\n",
    "        return actions['right']\n",
    "            \n",
    "    \n",
    "    if velocity > 0: # going up in left or right\n",
    "        \n",
    "        if prevPos > position: # going left\n",
    "            prevV = velocity\n",
    "            prevPos = position\n",
    "            # print(\"going up-left action left\")\n",
    "            return actions['left']\n",
    "        else:\n",
    "            prevV = velocity\n",
    "            prevPos = position\n",
    "            # print(\"going up-right action right\")\n",
    "            return actions['right']\n",
    "    \n",
    "    \n",
    "    if prevPos > position: \n",
    "        prevV = velocity\n",
    "        prevPos = position\n",
    "        # print(\"going down-left action left\")\n",
    "        return actions['left']\n",
    "    else:\n",
    "        prevV = velocity\n",
    "        prevPos = position\n",
    "        # print(\"going down-right action left\")\n",
    "        return actions['right']\n",
    "    \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Well done!\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize=(4, 3))\n",
    "# display.clear_output(wait=True)\n",
    "\n",
    "obs = env.reset()\n",
    "for t in range(TIME_LIMIT):\n",
    "    # plt.gca().clear()\n",
    "    \n",
    "    action = policy(obs, t)  # Call your policy\n",
    "    obs, reward, done, _ = env.step(action)  # Pass the action chosen by the policy to the environment\n",
    "    \n",
    "    # We don't do anything with reward here because MountainCar is a very simple environment,\n",
    "    # and reward is a constant -1. Therefore, your goal is to end the episode as quickly as possible.\n",
    "\n",
    "    # Draw game image on display.\n",
    "    env.render()\n",
    "    # plt.imshow(env.render('rgb_array'))\n",
    "    \n",
    "    # display.display(plt.gcf())\n",
    "    # display.clear_output(wait=True)\n",
    "\n",
    "    if done:\n",
    "        print(\"Well done!\")\n",
    "        break\n",
    "    # print(f\"time step {t}\")\n",
    "    # print(obs)\n",
    "else:\n",
    "    print(\"Time limit exceeded. Try again.\")\n",
    "\n",
    "# display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You solved it!\n"
     ]
    }
   ],
   "source": [
    "assert obs[0] > 0.47\n",
    "print(\"You solved it!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
